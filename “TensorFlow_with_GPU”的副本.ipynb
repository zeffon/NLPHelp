{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“TensorFlow with GPU”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeffon/NLPHelp/blob/master/%E2%80%9CTensorFlow_with_GPU%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "de20869e-731f-43b3-b275-48b59c9827a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KjbNEcWwHy9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-3kqZCeH0Qq",
        "colab_type": "code",
        "outputId": "9f5b0ee7-3530-421b-e540-9dbf8fbf82a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Y2_ELN5M2pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import codecs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import jieba\n",
        "import jieba.analyse  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFD0VJm7tSY3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JWFlamwPAQe",
        "colab_type": "code",
        "outputId": "52b50ba5-5c62-4482-95c8-cd68dfa04354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding, Flatten, Dropout, GlobalAveragePooling1D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6doQKzlJOz-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_root_path = '.'\n",
        "STOPWORDS_PATH = './stopwords0.txt'\n",
        "raw_train_data_path = 'comments_train.csv'\n",
        "raw_test_data_path = 'comments_test.csv'\n",
        "train_data_path = os.path.join(raw_root_path, raw_train_data_path)\n",
        "test_data_path = os.path.join(raw_root_path, raw_test_data_path)\n",
        "df_train_data = pd.read_csv(train_data_path, encoding='utf-8').sample(frac=1).iloc[:6000, :]\n",
        "df_test_data = pd.read_csv(test_data_path, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQI-Md9SOhoH",
        "colab_type": "code",
        "outputId": "ed50ba73-7643-49be-d142-c06d78179e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>1828</td>\n",
              "      <td>为什么界面总是加载不出来哇哇哇！！！</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2027</th>\n",
              "      <td>2027</td>\n",
              "      <td>越来越有意思了。虽然反反复复的看，跟着做印象深。</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2671</th>\n",
              "      <td>2671</td>\n",
              "      <td>全新的学习体验，非常棒</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5067</th>\n",
              "      <td>5067</td>\n",
              "      <td>不知道实验室还是要计时的，不知道是不是计时结束会有收费？</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>2026</td>\n",
              "      <td>挺好的，不过现在是上班时间，等下班了再来学习</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                       comment  label\n",
              "1828  1828            为什么界面总是加载不出来哇哇哇！！！      0\n",
              "2027  2027      越来越有意思了。虽然反反复复的看，跟着做印象深。      2\n",
              "2671  2671                   全新的学习体验，非常棒      2\n",
              "5067  5067  不知道实验室还是要计时的，不知道是不是计时结束会有收费？      0\n",
              "2026  2026        挺好的，不过现在是上班时间，等下班了再来学习      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "SF0nmSS4OwS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_wordlist(row):\n",
        "    result = re.sub('[^\\u4e00-\\u9fa5?!]', \"\", row)\n",
        "    f1_seg_list = jieba.cut(result)#需要添加一个词典，来弥补结巴分词中没有的词语，从而保证更高的正确率\n",
        "    f_stop = codecs.open(STOPWORDS_PATH,\"r\",\"utf-8\")\n",
        "    try:\n",
        "        f_stop_text = f_stop.read()\n",
        "    finally:\n",
        "        f_stop.close()\n",
        "    f_stop_seg_list = f_stop_text.split()\n",
        "    test_words = []\n",
        "    for myword in f1_seg_list:\n",
        "        test_words.append(myword)\n",
        "#         if myword not in f_stop_seg_list:\n",
        "#             test_words.append(myword)\n",
        "    result = ' '.join(test_words)\n",
        "    return result\n",
        "\n",
        "def Textrank(content):\n",
        "    result = re.sub(r'[^\\u4e00-\\u9fa5?!]', \"\",content)\n",
        "    seg = jieba.cut(result)  \n",
        "    jieba.analyse.set_stop_words(STOPWORDS_PATH)\n",
        "    keyList=jieba.analyse.textrank('|'.join(seg), topK=10, withWeight=False)  \n",
        "    return keyList\n",
        " \n",
        "def TF_IDF(content):\n",
        "    result = re.sub(r'[^\\u4e00-\\u9fa5?!]', \"\",content)\n",
        "    seg = jieba.cut(result)  \n",
        "    jieba.analyse.set_stop_words(STOPWORDS_PATH)\n",
        "    keyWord = jieba.analyse.extract_tags(  \n",
        "        '|'.join(seg), topK=20, withWeight=False, allowPOS=())#关键词提取，在这里对jieba的tfidf.py进行了修改   \n",
        "    return keyWord\n",
        "def convert_TF_IDF(content):\n",
        "    result = TF_IDF(content)\n",
        "    result = ' '.join(result)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJt4GkEeO20W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_y_data = df_train_data.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jq9zAp7XO3HX",
        "colab_type": "code",
        "outputId": "f829396e-7f87-450d-c0f1-d3ed76f2a7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = df_train_data.comment.map(convert_TF_IDF)\n",
        "train_data[:5]\n",
        "type(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.066 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hMXviH17o1Dm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuQmjge2O6J-",
        "colab_type": "code",
        "outputId": "9583fcb9-1760-4ac0-9ad5-cce448fa3a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# vect = TfidfVectorizer(max_features=5000)\n",
        "vect = TfidfVectorizer(min_df=6, max_features=800)\n",
        "train_data_v = vect.fit_transform(train_data)\n",
        "print('count features: {}'.format(len(vect.vocabulary_)))\n",
        "# print(' features: {}'.format(vect.vocabulary_))\n",
        "# print(repr(train_data_v.toarray()[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count features: 800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2KTu28WBO9C-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_data_v, train_y_data, test_size=0.2, random_state=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKOfCUaiyUmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJFzffM0PDBo",
        "colab_type": "code",
        "outputId": "6dd924d8-9db2-4584-91d8-603daff6bbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "print('-----before reshape-------')\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(val_x.shape)\n",
        "print(val_y.shape)\n",
        "\n",
        "n_words = vect.vocabulary_\n",
        "max_features = n_words\n",
        "batch_size = 120\n",
        "timesteps = 4\n",
        "\n",
        "train_x_r = train_x.toarray().reshape([1200 * 4, timesteps, int(train_x.shape[1]/timesteps)])\n",
        "train_y_r = keras.utils.to_categorical(train_y, num_classes=4)\n",
        "val_x_r = val_x.toarray().reshape([1200 * 1, timesteps, int(val_x.shape[1]/timesteps)])\n",
        "val_y_r = keras.utils.to_categorical(val_y, num_classes=4)\n",
        "\n",
        "print('-----after reshape-------')\n",
        "print(train_x_r.shape)\n",
        "print(train_y_r.shape)\n",
        "print(val_x_r.shape)\n",
        "print(val_y_r.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----before reshape-------\n",
            "(4800, 800)\n",
            "(4800,)\n",
            "(1200, 800)\n",
            "(1200,)\n",
            "-----after reshape-------\n",
            "(4800, 4, 200)\n",
            "(4800, 4)\n",
            "(1200, 4, 200)\n",
            "(1200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zXpmu6aaPFCL",
        "colab_type": "code",
        "outputId": "a29d6d35-e8ee-4cad-8865-0935ae774bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data_dim = train_x_r.shape[2]\n",
        "\n",
        "tbc=TensorBoardColab()\n",
        "\n",
        "model = Sequential()\n",
        "# model.add(Embedding(len(n_words)+1, 32, input_length=data_dim))\n",
        "# model.add(LSTM(32, return_sequences=True, stateful=True, ))\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
        "               batch_input_shape=(batch_size, timesteps, data_dim),\n",
        "               kernel_regularizer=regularizers.l2(0.001), \n",
        "               recurrent_regularizer=regularizers.l2(0.01), \n",
        "               bias_regularizer=regularizers.l2(0.001),\n",
        "              ))\n",
        "# model.add(Dropout(rate=0.01, noise_shape=(batch_size, timesteps, 32), seed=1))\n",
        "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
        "# model.add(Dropout(rate=0.01, noise_shape=(batch_size, timesteps, 32), seed=1))\n",
        "model.add(LSTM(32, stateful=True))\n",
        "# model.add(Dropout(rate=0.01, noise_shape=(batch_size, 32), seed=1))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "model.fit(train_x_r, train_y_r,\n",
        "          batch_size=batch_size, \n",
        "          epochs=50, \n",
        "          shuffle=True,\n",
        "          validation_data=(val_x_r, val_y_r),\n",
        "          callbacks=[TensorBoardColabCallback(tbc)]\n",
        "         )\n",
        "\n",
        "score, acc = model.evaluate(val_x_r, val_y_r,\n",
        "                            batch_size=batch_size)\n",
        "print('score: {}'.format(score))\n",
        "print('acc: {}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7jKwEL7NlEt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKAjTRoTIWPi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}